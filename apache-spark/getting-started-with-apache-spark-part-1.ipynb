{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Apache Spark - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook code supports the blog:  \n",
    "https://medium.com/expedia-group-tech/start-your-journey-with-apache-spark-part-1-3575b20ee088."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Reuired Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SparkSession and SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RDD from a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = [1,2,3,4,5]\n",
    "num_rdd = sc.parallelize(num)\n",
    "num_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "* As we know, Transformations are lazy in nature and they will not be executed until an Action is executed on top of them. \n",
    "* Let’s try to understand various available Transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map\n",
    "* This will map your input to some output based on the function specified in the map function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_rdd = num_rdd.map(lambda x : x * 2)\n",
    "double_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter\n",
    "* To filter the data based on a certain condition. Let’s try to find the even numbers from num_rdd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_rdd = num_rdd.filter(lambda x : x % 2 == 0)\n",
    "even_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatMap\n",
    "* This function is very similar to map, but can return multiple elements for each input in the given RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1, 2, 3, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_rdd = num_rdd.flatMap(lambda x : range(1,x))\n",
    "flat_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distinct\n",
    "* This will return distinct elements from an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 11, 12]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([10, 11, 10, 11, 12, 11])\n",
    "dist_rdd = rdd1.distinct()\n",
    "dist_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduceByKey\n",
    "* This function reduces the key values pairs based on the keys and a given function inside the reduceByKey. Here’s an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 8)\n",
      "('b', 8)\n",
      "('c', 6)\n"
     ]
    }
   ],
   "source": [
    "pairs = [ (\"a\", 5), (\"b\", 7), (\"c\", 2), (\"a\", 3), (\"b\", 1), (\"c\", 4)]\n",
    "pair_rdd = sc.parallelize(pairs)\n",
    "output = pair_rdd.reduceByKey(lambda x, y : x + y)\n",
    "result = output.collect()\n",
    "print(*result, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupByKey\n",
    "* This function is another ByKey function which can operate on a (key, value) pair RDD but this will only group the values based on the keys. In other words, this will only perform the first step of reduceByKey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_out = pair_rdd.groupByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sortByKey\n",
    "* This function will perform the sorting on a (key, value) pair RDD based on the keys. By default, sorting will be done in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 5)\n",
      "('b', 3)\n",
      "('c', 2)\n",
      "('d', 7)\n"
     ]
    }
   ],
   "source": [
    "pairs = [ (\"a\", 5), (\"d\", 7), (\"c\", 2), (\"b\", 3)]\n",
    "raw_rdd = sc.parallelize(pairs)\n",
    "sortkey_rdd = raw_rdd.sortByKey()\n",
    "result = sortkey_rdd.collect()\n",
    "print(*result,sep='\\n')\n",
    "\n",
    "# Note: for sorting in descending order pass “ascending=False”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sortBy\n",
    "* sortBy is a more generalized function for sorting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('b', 3, 9)\n",
      "('a', 5, 10)\n",
      "('c', 2, 11)\n",
      "('d', 7, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create RDD.\n",
    "pairs = [ (\"a\", 5, 10), (\"d\", 7, 12), (\"c\", 2, 11), (\"b\", 3, 9)]\n",
    "raw_rdd = sc.parallelize(pairs)\n",
    "\n",
    "# Let’s try to do the sorting based on the 3rd element of the tuple.\n",
    "sort_out = raw_rdd.sortBy(lambda x : x[2])\n",
    "result = sort_out.collect()\n",
    "print(*result, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions\n",
    "* Actions are operations on RDDs which execute immediately. While Transformations return another RDD, Actions return language native data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count\n",
    "* This will count the number of elements in the given RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = sc.parallelize([1,2,3,4,2])\n",
    "num.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first\n",
    "* This will return the first element from given RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect\n",
    "* This will return all the elements for the given RDD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 2]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note: We should not use the collect operation while working with large datasets. Because it will return all the data which is distributed across the different workers of your cluster to a driver. All the data will travel across the network from worker to driver and also the driver would need to hold all the data. This will hamper the performance of your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take\n",
    "* This will return the number of elements specified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference for more Transformations and Actions\n",
    "* https://spark.apache.org/docs/latest/rdd-programming-guide.html?source=post_page3575b20ee088#actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You - End of Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

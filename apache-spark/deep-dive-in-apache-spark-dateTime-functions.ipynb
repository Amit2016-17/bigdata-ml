{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dive in Apache Spark DateTime functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook code supports the blog:  \n",
    "#### Link to be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Reuired Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SparkSession and SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = [(1, \"AAA\", \"dept1\", 1000, \"2019-02-01 15:12:13\"),\n",
    "    (2, \"BBB\", \"dept1\", 1100, \"2018-04-01 5:12:3\"),\n",
    "    (3, \"CCC\", \"dept1\", 3000, \"2017-06-05 1:2:13\"),\n",
    "    (4, \"DDD\", \"dept1\", 1500, \"2019-08-10 10:52:53\"),\n",
    "    (5, \"EEE\", \"dept2\", 8000, \"2016-01-11 5:52:43\"),\n",
    "    (6, \"FFF\", \"dept2\", 7200, \"2015-04-14 19:32:33\"),\n",
    "    (7, \"GGG\", \"dept3\", 7100, \"2019-02-21 15:42:43\"),\n",
    "    (8, \"HHH\", \"dept3\", 3700, \"2016-09-25 15:32:33\"),\n",
    "    (9, \"III\", \"dept3\", 4500, \"2017-10-15 15:22:23\"),\n",
    "    (10, \"JJJ\", \"dept5\", 3400, \"2018-12-17 15:14:17\")]\n",
    "empdf = spark.createDataFrame(emp, [\"id\", \"name\", \"dept\", \"salary\", \"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date|next_month|\n",
      "+-------------------+----------+\n",
      "|2019-02-01 15:12:13|2019-03-01|\n",
      "|  2018-04-01 5:12:3|2018-05-01|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the months to the date. It will return new date after the month from the start date.\n",
    "# For e.g. in below statement we have added 1 months to the column \"date\" and generated new column as \"next_month\"\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"next_month\", add_months(\"date\", 1)))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|current_date|\n",
      "+---+------------+\n",
      "|  1|  2019-10-09|\n",
      "|  2|  2019-10-09|\n",
      "+---+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return current date.\n",
    "df = (empdf\n",
    "    .withColumn(\"current_date\", current_date())\n",
    "    .select(\"id\", \"current_date\"))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+\n",
      "|id |current_timestamp      |\n",
      "+---+-----------------------+\n",
      "|1  |2019-10-09 20:55:07.696|\n",
      "|2  |2019-10-09 20:55:07.696|\n",
      "+---+-----------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return current timestamp.\n",
    "df = (empdf\n",
    "    .withColumn(\"current_timestamp\", current_timestamp())\n",
    "    .select(\"id\", \"current_timestamp\"))\n",
    "df.show(2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date| next_date|\n",
      "+-------------------+----------+\n",
      "|2019-02-01 15:12:13|2019-02-06|\n",
      "|  2018-04-01 5:12:3|2018-04-06|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will gives the date days after the start date mentioned in the function.\n",
    "# for example below statement will return the date after say 5 days in new column as \"next_date\"\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"next_date\", date_add(\"date\", 5)))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date|  new_date|\n",
      "+-------------------+----------+\n",
      "|2019-02-01 15:12:13|01/02/2019|\n",
      "|  2018-04-01 5:12:3|01/04/2018|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the date to specified format.\n",
    "# For e.g. we will convert the date from \"yyyy-MM-dd\" to \"dd/MM/yyyy\" format.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"new_date\", date_format(\"date\", \"dd/MM/yyyy\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date|  new_date|\n",
      "+-------------------+----------+\n",
      "|2019-02-01 15:12:13|2019-01-27|\n",
      "|  2018-04-01 5:12:3|2018-03-27|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return the days before the start date. Opposite of date_add.\n",
    "# for example below statement will return the date before say 5 days in new column as \"new_date\"\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"new_date\", date_sub(\"date\", 5)))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date_trunc : based on year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|               date|           new_date|\n",
      "+-------------------+-------------------+\n",
      "|2019-02-01 15:12:13|2019-01-01 00:00:00|\n",
      "|  2018-04-01 5:12:3|2018-01-01 00:00:00|\n",
      "+-------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return timestamp truncated to the specified unit.\n",
    "# Lets truncate date by year. we can use \"yyyy\" or \"yy\" or\" \"year\" to specify Year.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"new_date\", date_trunc(\"year\", \"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date_trunc : based on Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|               date|           new_date|\n",
      "+-------------------+-------------------+\n",
      "|2019-02-01 15:12:13|2019-02-01 00:00:00|\n",
      "|  2018-04-01 5:12:3|2018-04-01 00:00:00|\n",
      "+-------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets truncate date by Month. we can use \"mm\" or \"month\" or\" \"mon\" to specify Month.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"new_date\", date_trunc(\"month\", \"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date_trunc : based on Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|               date|           new_date|\n",
      "+-------------------+-------------------+\n",
      "|2019-02-01 15:12:13|2019-02-01 00:00:00|\n",
      "|  2018-04-01 5:12:3|2018-04-01 00:00:00|\n",
      "+-------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets truncate date by Day. we can use \"day\" or \"dd\"  to specify Day.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"new_date\", date_trunc(\"day\", \"date\")))\n",
    "df.show(2)\n",
    "\n",
    "# Note can use these many formats to truncate the date based on different level.\n",
    "# Format : ‘year’, ‘yyyy’, ‘yy’, ‘month’, ‘mon’, ‘mm’, ‘day’, ‘dd’, ‘hour’, ‘minute’, ‘second’, ‘week’, ‘quarter’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datediff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+---------+\n",
      "|               date|current_date|date_diff|\n",
      "+-------------------+------------+---------+\n",
      "|2019-02-01 15:12:13|  2019-10-09|      250|\n",
      "|  2018-04-01 5:12:3|  2019-10-09|      556|\n",
      "+-------------------+------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return the difference between the dates in terms of days\n",
    "# Lets add another column as current date and takes the difference with \"date\" column here.\n",
    "df = (empdf.select(\"date\")\n",
    "        # Add another date column as current date.\n",
    "        .withColumn(\"current_date\", current_date()) \n",
    "        # Take the difference between current_date and date column.\n",
    "        .withColumn(\"date_diff\", datediff(\"current_date\", \"date\"))) \n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dayofmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date|dayofmonth|\n",
      "+-------------------+----------+\n",
      "|2019-02-01 15:12:13|         1|\n",
      "|  2018-04-01 5:12:3|         1|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return the date of the month.\n",
    "# For e.g. for 5th Jan 2019 (2019-01-05) it will return 5. \n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"dayofmonth\", dayofmonth(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|               date|dayofweek|\n",
      "+-------------------+---------+\n",
      "|2019-02-01 15:12:13|        6|\n",
      "|  2018-04-01 5:12:3|        1|\n",
      "+-------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# it will return day of week as integer. It will consider Sunday as 1st day and Saturday as 7th Day.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"dayofweek\", dayofweek(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|               date|dayofyear|\n",
      "+-------------------+---------+\n",
      "|2019-02-01 15:12:13|       32|\n",
      "|  2018-04-01 5:12:3|       91|\n",
      "+-------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return day of the year as integer.\n",
    "# For e.g. for 5th Jan it will return 5. for 1st Feb it will return 32.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"dayofyear\", dayofyear(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from_utc_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|               date|      pst_timestamp|\n",
      "+-------------------+-------------------+\n",
      "|2019-02-01 15:12:13|2019-02-01 07:12:13|\n",
      "|  2018-04-01 5:12:3|2018-03-31 22:12:03|\n",
      "+-------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert UTC timestamp to timestamp of any specified timezone. Default, it will assume that date is in UTC timestamp.\n",
    "# For e.g. lets convert the UTC timestamp to \"PST\" time.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"pst_timestamp\", from_utc_timestamp(\"date\", \"PST\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+\n",
      "|               date|unix_timestamp|\n",
      "+-------------------+--------------+\n",
      "|2019-02-01 15:12:13|    1549033933|\n",
      "|  2018-04-01 5:12:3|    1522559523|\n",
      "+-------------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp string with given format to Unix time stamp (in Seconds). Default format is \"yyyy-MM-dd HH:mm:ss\".\n",
    "# You can use spark property : \"spark.sql.session.timeZone\" to set the timezone.\n",
    "\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"unix_timestamp\", unix_timestamp(\"date\", \"yyyy-MM-dd HH:mm:ss\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-------------------+\n",
      "|               date|unix_timestamp| date_from_unixtime|\n",
      "+-------------------+--------------+-------------------+\n",
      "|2019-02-01 15:12:13|    1549033933|2019-02-01 15:12:13|\n",
      "|  2018-04-01 5:12:3|    1522559523|2018-04-01 05:12:03|\n",
      "+-------------------+--------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converts the number of seconds from unix epoch (1970-01-01 00:00:00 UTC) to a given string format. You can set the timezone and format as well.\n",
    "# You can use spark property : \"spark.sql.session.timeZone\" to set the timezone.\n",
    "\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    # Convert timestamp to unix timestamp.\n",
    "    .withColumn(\"unix_timestamp\", unix_timestamp(\"date\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    # Convert unix timestamp to timestamp.\n",
    "    .withColumn(\"date_from_unixtime\", from_unixtime(\"unix_timestamp\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+\n",
      "|               date|hour|\n",
      "+-------------------+----+\n",
      "|2019-02-01 15:12:13|  15|\n",
      "|  2018-04-01 5:12:3|   5|\n",
      "+-------------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return hour part of the date.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"hour\", hour(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### last_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date| last_date|\n",
      "+-------------------+----------+\n",
      "|2019-02-01 15:12:13|2019-02-28|\n",
      "|  2018-04-01 5:12:3|2018-04-30|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return last of the Month for a given date.\n",
    "# For e.g. for 5th Jan 2019, it will return 31st Jan 2019, since this is the last date for the Month.\n",
    "\n",
    "df = empdf.select(\"date\").withColumn(\"last_date\", last_day(\"date\"))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|               date|minute|\n",
      "+-------------------+------+\n",
      "|2019-02-01 15:12:13|    12|\n",
      "|  2018-04-01 5:12:3|    12|\n",
      "+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return minute part of the date.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"minute\", minute(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|               date|month|\n",
      "+-------------------+-----+\n",
      "|2019-02-01 15:12:13|    2|\n",
      "|  2018-04-01 5:12:3|    4|\n",
      "+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return month part of the date.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"month\", month(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### months_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------------+\n",
      "|               date|current_date|months_between|\n",
      "+-------------------+------------+--------------+\n",
      "|2019-02-01 15:12:13|  2019-10-09|    8.23762955|\n",
      "|  2018-04-01 5:12:3|  2019-10-09|   18.25107415|\n",
      "+-------------------+------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return the difference between the dates in terms of months. \n",
    "# If first date is greater than second one result will be positive else negative.\n",
    "# For e.g. between 6th Feb 2019 and 5th Jan 2019 it will return 1.\n",
    "\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    # Add another date column as current date.        \n",
    "    .withColumn(\"current_date\", current_date()) \n",
    "    # Take the difference between current_date and date column in terms of months.\n",
    "    .withColumn(\"months_between\", months_between(\"current_date\", \"date\"))) \n",
    "df.show(2)\n",
    "\n",
    "# Note from Spark 2.4.0 onwards you can specify third argument \"roundOff=True\" to round-Off the value. \n",
    "# Default value is True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date|  next_day|\n",
      "+-------------------+----------+\n",
      "|2019-02-01 15:12:13|2019-02-03|\n",
      "|  2018-04-01 5:12:3|2018-04-08|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return the next day based on the dayOfWeek specified in next argument.\n",
    "# For e.g. for 1st Feb 2019 (Friday) if we ask for next_day as sunday, it will return 3rd Feb 2019.\n",
    "\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"next_day\", next_day(\"date\", \"sun\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|               date|quarter|\n",
      "+-------------------+-------+\n",
      "|2019-02-01 15:12:13|      1|\n",
      "|  2018-04-01 5:12:3|      2|\n",
      "+-------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return quarter of the given date as integer.\n",
    "\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"quarter\", quarter(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|               date|second|\n",
      "+-------------------+------+\n",
      "|2019-02-01 15:12:13|    13|\n",
      "|  2018-04-01 5:12:3|     3|\n",
      "+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return the second part of the date.\n",
    "\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"second\", second(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date|   to_date|\n",
      "+-------------------+----------+\n",
      "|2019-02-01 15:12:13|2019-02-01|\n",
      "|  2018-04-01 5:12:3|2018-04-01|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will convert the String or TimeStamp to Date.\n",
    "\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"to_date\", to_date(\"date\")))\n",
    "df.show(2)\n",
    "\n",
    "# Note : Check the data type of column \"date\" and \"to-date\".\n",
    "# If the string format is 'yyyy-MM-dd HH:mm:ss' then we need not to specify the format. \n",
    "# Otherwise, specify the format as second arg in to_date function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to_date with different date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date|  new_date|\n",
      "+-------------------+----------+\n",
      "|15/02/2019 10:30:00|2019-02-15|\n",
      "+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we will convert the string of format 'dd/MM/yyyy HH:mm:ss' to \"date\" data type. Default format it 'yyyy-MM-dd`.\n",
    "df1 = spark.createDataFrame([('15/02/2019 10:30:00',)], ['date'])\n",
    "df2 = (df1\n",
    "    .withColumn(\"new_date\", to_date(\"date\", 'dd/MM/yyyy HH:mm:ss')))\n",
    "    \n",
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|               date|           new_date|\n",
      "+-------------------+-------------------+\n",
      "|15/02/2019 10:30:00|2019-02-15 10:30:00|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will convert the String to TimeStamp. Here we will convert the string of format 'dd/MM/yyyy HH:mm:ss' to \"timestamp\" data type.\n",
    "# default format is 'yyyy-MM-dd HH:mm:ss'\n",
    "\n",
    "df1 = spark.createDataFrame([('15/02/2019 10:30:00',)], ['date'])\n",
    "df2 = (df1\n",
    "    .withColumn(\"new_date\", to_timestamp(\"date\", 'dd/MM/yyyy HH:mm:ss')))\n",
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to_utc_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|               date|      utc_timestamp|\n",
      "+-------------------+-------------------+\n",
      "|2019-02-01 15:12:13|2019-02-01 23:12:13|\n",
      "|  2018-04-01 5:12:3|2018-04-01 12:12:03|\n",
      "+-------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert given timestamp to UTC timestamp.\n",
    "# For e.g. lets convert the \"PST\" timestamp to \"UTC\" timestamp.\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"utc_timestamp\", to_utc_timestamp(\"date\", \"PST\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               date|weekofyear|\n",
      "+-------------------+----------+\n",
      "|2019-02-01 15:12:13|         5|\n",
      "|  2018-04-01 5:12:3|        13|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return the weekofyear for the given date.\n",
    "\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"weekofyear\", weekofyear(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+\n",
      "|               date|year|\n",
      "+-------------------+----+\n",
      "|2019-02-01 15:12:13|2019|\n",
      "|  2018-04-01 5:12:3|2018|\n",
      "+-------------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It will return the year part of the date.\n",
    "\n",
    "df = (empdf\n",
    "    .select(\"date\")\n",
    "    .withColumn(\"year\", year(\"date\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK YOU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
